# Logging

This outlines logging and visualization standards.

[[_TOC_]]

## Overview

We currently leverage the k8s pipeline that already does the following.

- Collects stdout and stderr streams from Docker
- Sends logs to AWS cloudwatch
- Ingests cloudwatch logs into Elasticsearch & Kibana platform

This has an application on the pipeline providing all the data needed to start logging and visualizing application data.

## Application Logging

For application logging, winston should be used to define a robust logging strategy for your application. Because containers are transient it's best to avoid file stream type logs unless you define your own strategy for moving the logs to a new location.

### Basics

Your application logging strategy should contain the following pieces at minimum:

1.) A breakdown of what kind of information you want to log at each applicable level [Logging Levels](https://github.com/winstonjs/winston#logging-levels)

2.) A configuration variable to set a logging level in each environment

3.) A default logger

A default logger in winston can be defined by re-configuring the winston export as the first thing you do in your server entry point (usually server.ts).

```javascript
import winston, { format } from 'winston';
winston.configure({
  format: format.combine(
    format.timestamp({ format: 'MM/DD/YYYY' }),
    format.json(),
  ),
  level: 'info',
  transports: [
    new winston.transports.Console({
      stderrLevels: ['error'],
      consoleWarnLevels: ['warn'],
    }),
  ],
});
```

This would let you use the basic winston logger for your most common usecases.

### Network Traffic

Network traffic can be captured in express/node with morgan - an http traffic monitor that outputs logs similar to apache. You can leverage winston to define your logging strategy for this kind of traffic as well.

```javascript
import morgan from 'morgan';
import logger from 'winston';
app.use(
  morgan('time=:date[clf] ip=:remote-addr method=:method url=:url status=:status response=:response-time ms', {
    stream: { write: message => logger.info(message) },
  }),
);
```

This would output a log that looks like this:

> {"message":"time=11/May/2020:16:55:30 +0000 ip=::1 method=GET url=/assets/spellbook.css status=304 response=3.288 ms\n","level":"info","timestamp":"11/05/2020:12:55:30"}

### API Traffic

Currently, the most compatible way to collect API traffic details involve logging from the proxyMiddleware used by most UI applications.

```javascript
  onProxyRes: (proxyRes: IncomingMessage, req: IncomingMessage) => {
    const log = {
      method: req?.method,
      url: req?.url,
      code: proxyRes?.statusCode,
      status: proxyRes?.statusMessage,
    };

    if (proxyRes?.statusCode === 200) {
      logger.info(log);
    } else {
      logger.error(log);
    }
  }
```

### Custom Traffic

You can leverage the winston logger (or a custom logger) either through the main API or through the various helper functions that define the "level" for you.

```javascript
logger.log({
  level: "info",
  message: "Info level logging"
});
logger.info("Info level logging");
logger.warn("Warn level logging");
logger.error('Error level logging');
```

## ELK - Elasticsearch, Logstash, Kibana

### Log access

[Non-prod Logs](https://vpc-adsales-eks-logging-oko3x5fswx4qzogu7rejtvj5ze.us-west-2.es.amazonaws.com/_plugin/kibana/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-15m,mode:quick,to:now))&_a=(columns:!(_source),index:aab2d8d0-8e10-11ea-9906-7d9aab8a76d8,interval:auto,query:(language:lucene,query:%27%27),sort:!(%27@timestamp%27,desc)))

[Production Logs](https://vpc-adsales-eks-logs-5z4ydznzmshxgpfy4opnnqto5e.us-west-2.es.amazonaws.com/_plugin/kibana/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-30d,mode:quick,to:now))&_a=(columns:!(_source),index:b2ae4470-49cd-11ea-ab81-91032dd88390,interval:auto,query:(language:lucene,query:'kubernetes.namespace_name:%20%22tribes-prod%22'),sort:!('@timestamp',desc)))

### Log Aggregation

stdout and stderr are collected from Kubernetes. One thing to note, pretty printing to the console will cause every line of a pretty print to output a new log. This should be avoided.

If you wish to output objects or JSON, just make sure winston is not pretty printing the contents.

### Locating Logs

Elasticsearch provides a custom query language for accessing log information that resembles what you would see in Cloudwatch Insights, Splunk, etc. The full extent of the query language is beyond this document but here are some tips for finding your application.

#### Namespace

You can search namespaces with kubernetes.namespace_name. In this case, namespace would refer to the tribe you deployed under.

> kubernetes.namespace_name: "ep-swe-softsol-dev"

> kubernetes.namespace_name: "tribes-prod"

#### Pod Name

Pod name will refer to the name of your kubernetes pod. This usually contains your application name, ie. release-notes-ui or tribes-ui, but also a unique hash. These get regenerated on new deploys. In order to capture the full extent of your application logs you can use a wildcard search.

> kubernetes.pod_name: "release-notes-ui*"

> kubernetes.pod_name: "tribes-ui*"

#### Stream type

Kubernetes automatically separated stdout stream from stderr - making an easy way to divide up strict errors from more verbose error logging.

> stream: "stderr"

> stream: "stdout"

#### Helpful Documents

- [Simple Searches](https://logz.io/blog/elasticsearch-queries/)
- [Advanced Queries](https://elasticsearch-cheatsheet.jolicode.com/)

## Kibana (Visualization)

### Dashboard

You should setup a dashboard that shows the basics of your application at a glance.

#### Naming Conventions

Dashboards and Visualizations require a unique name in Kibana. Because visualizations are often accessed by non-developers to view an application the naming should be semantic. For example, instead of **release-notes-ui-dashboard** call it **Release Notes UI Dashboard**.

Visualizations use the name as the widget title on the dashboard and should follow similar conventions - but make sure you name it specific enough that you'll understand what it means when importing it.

> Release Notes UI - Traffic Logs

> Release Notes UI - Error Logs

> Release Notes UI - Status Code Aggregation

#### Recommended Visualizations

Some recommendations to start your application dashboard.

1.) You can display saved searches in a table widget. It's good practice to create saved searches and tables for general logs + error logs for easy log access.

2.) Basic network metrics - number of requests, status code counts, etc

3.) Trend diagrams showing changes in key metrics - for example error count over time

### Alerts

Alerts in Kibana are handled with three pieces - a monitor, a trigger, and an audience.

#### Monitor

A monitor tracks an occurance or number of occurances over a period of time. For example, you can search the logs for the string **PIXAR** in the logs within the last 15 minute period. Monitors are made up of: A time interval, a query, and an index.

**Example alarm:**

> Run every 1 minute

> Index: cwl-*

> Query: Instances of **PIXAR** with a kubernetes pod name of **release-notes-ui\***

```
{
    "size": 0,
    "query": {
        "bool": {
            "must": [
                {
                    "query_string": {
                        "query": "(kubernetes.namespace_name:\"ep-swe-softsol-dev\") AND (kubernetes.pod_name:\"release-notes-ui*\") AND (log:*PIXAR*)",
                        "analyze_wildcard": true
                    }
                }
            ],
            "filter": [
                {
                    "range": {
                        "@timestamp": {
                            "from": "{{period_start}}",
                            "to": "{{period_end}}",
                            "include_lower": true,
                            "include_upper": true,
                            "boost": 1
                        }
                    }
                }
            ]
        }
    }
}
```

#### Trigger

A trigger as the name suggests tells you what kind of result should you alarm on. The most basic trigger would be the # of results > 0.

> ctx.results[0].hits.total > 0

Triggers use a syntax called Painless scripts for more complex results.

#### Audience

Your audience will be defined by an SNS topic, Slack channel, or Custom Webhook

#### Helpful Docs

- https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html

- https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-guide.html

## AWS CloudWatch

In cases where an ELK stack is unavailable or inappropriate you can directly leverage the AWS CloudWatch logging mechanism. All infastructure should be reporting into a CloudWatch group of some kind. If your application currently does not have any log aggregation at this level that would be the first step for improving logging & observability.

### Access

You will need the following read-only account access for directly viewing cloudwatch logs.

- dtsspcm-service-admin (AWS: 676699563051)
- TBD (AWS: 416487218034)

Production access can be requested in the [INFAENG](https://jira.disney.com/projects/INFRAENG) JIRA board. Non-production is in a state of flux. For now, you can ask the development team the best way to get access during this period.

### Log Groups

For typical UI Engineering projects, you should expect to find logs in the following:

- Region - us-west-2
- Log Group (Non-Prod) - adsales-nonprod-eks
- Log Group (Prod) - adsales-prod-eks

### Insights

CloudWatch Insights can be used to directly query the log files in the application log group. Make sure to select your time range and log group before continuing. The following examples primarily use LIKE queries for simplicity but may not be performant. 

**Basic Query:**

```
fields @timestamp, @message
| filter kubernetes.namespace_name like /ep-swe-softsol-dev/
| filter kubernetes.pod_name like /endgame/
| filter @message like /My App Error/
| sort @timestamp desc
| limit 20

```

**Common Filters:**

- kubernetes.namespace_name - The current namespace on the cluster that the application is deployed to
- kubernetes.pod_name - This will be the application name + a unique hash, ie. endgame-864b84bd7-tqvhn. Use a LIKE query to get all pods running your application simultaneously. 
- @message - The recorded log message from your application. May be a string or object depending on your logging strategy.
- @timestamp - When the log occured
- limit - Number of results to return

### References

- [Insights Query Syntax](https://docs.amazonaws.cn/en_us/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html)
- [CloudWatch](https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#)

## Grafana

We are currently looking into Grafana as a visualization, aggregation, and alerting tool.

### Accessing Logs

Grafana can query CloudWatch logs directly with Insights syntax. For the basic use case of using Grafana you can see the insights guide and syntax help. Currently, you can only query the production cluster.

1. Select "Explore" to start building a query against a datasource
2. Select "Cloudwatch - DTCI UPIC Adsales" as the datasource
3. Set "Query Mode" to "CloudWatch Logs"
4. Select "us-west-2" as your region
5. Select "adsales-prod-eks" as your log group
6. Create a suitable Insights query for your application

### Create Dashboard

1. Select the "+" sign and choose to creare a new dashboard
2. Click the save button to name your dashboard and use "UIET" as the folder

 ![Alt text](graphics/grafana_create_dashboard.png?raw=true "Create Dashboard")

### Create Panel

Select create a panel to get started. You can configure the type of panel under "Visualizations", ie.

1. Text / Markdown - Text provided by you, the user!
2. Graph / Stat / Etc - Visual representations of your data
3. Table / Logs - Record views

 ![Alt text](graphics/grafana_settings_overview.png?raw=true "Grafana Settings")

#### Panel Query - New Relic

Because of the way the API works the application list can take awhile to finish loading. This is a one time nusience. To make it easier, you can duplicate existing panels with a new relic query with your application already selected. You can explore available metrics in [New Relic Insights Data Explorer](https://insights.newrelic.com/accounts/1255599/explorer/metrics).

You can provide queries by providing application name, metric name, and metric value 

 ![Alt text](graphics/newrelic_grafana_query.png?raw=true "NewRelic Query")


#### Panel Query - CloudWatch

Select the appropriate AWS Environment / Log Group and then provide a CloudWatch query (see [Tracing](tracing.md) for an example).

 ![Alt text](graphics/cloudwatch_grafana_query.png?raw=true "CloudWatch Query")

### References

- [Grafana](https://grafana.dtci.technology/)